# Image-Captioning
PROBLEM STATEMENT
Now days, if someone see the image and not able to recognise what image is showing. Then in that Scanerio Image Captioning would help the user to get the final output of the image.

If there is an user with medical conditions like blind and paralysis then they might able to use any technology for recognising the image. Our project Image Captioning with Voice recognition would help the user to get the final output.

So Image caption, automatically generating natural language descriptions according to the content observed in an image, is an important part of scene understanding, which combines the knowledge of computer vision and natural language processing. The application of image caption is extensive and significant, for example, the realization of human-computer interaction.

WHAT IS IMAGE CAPTION?

Image Captioning is the process of generating textual description of an image. It uses Machine Learning, Deep Learning, Natural Language Processing and Computer Vision to generate the captions. The dataset will be in the form image to captions. The dataset consists of input images and their corresponding output captions.

**Dataset**

The Flickr 8k dataset have five different descriptions per image, that provide clear descriptions of the noticeable entities and events and are described by actual people. The dataset has 8000 images from Flickr and contains people and animals (mostly dogs) performing some action. We used ¾ of the data for training and ¼ for evaluation.
1. lowercase all words
2. remove punctuation like .,-<>()
3. remove hanging ‘s’ and ‘a’
4. remove numbers

Models used:
CNN, RNN , LSTM models has been used here. 

Deployment:
Deployed it on heroku. 

